# -*- coding: utf-8 -*-
"""GeoReservoir4B4inLocalV4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQnRQ-g-218Ozn3kBLxvwlUgvasm2son

# GeoAoi用
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import linalg 
import random
import os
import time
# numpy.linalg is also an option for even fewer dependencies
#日付を取得してデータを取得
import datetime

"""# function"""

def dis_in_out(Data,inSize,outSize,dis):
  W = int(np.ceil(Data.shape[1]/dis))-1 #In,Outの横の長さ
  In = np.zeros((inSize,W)) #Dataの横の長さをdis分割してお尻だけ削る
  Out = np.zeros((outSize,W)) #頭だけ削る
  for i in range(W):
    In[0:inSize, i] = Data[0:inSize, i*dis] #頭からdisおきに格納
    Out[0:outSize, i] = Data[0:outSize, i*dis + dis] #Inに対してdis後が正解
  return (In,Out)

def print_MSE(teacher, output, inputScaling, name, is_save, is_show, ylim=0):
  if len(teacher) != len(output):
    print("print_MSE ERROR not same")
    return
  se = np.zeros(len(output))
  tmp_mse = []
  for i in range(len(output)):
    se[i] =  np.square( (output[i] - teacher[i])/inputScaling )
    # tmp_mse.append(np.sqrt(se.sum()/(i+1)))
    tmp_mse.append((output[i] - teacher[i])/inputScaling)

  mse = np.sqrt(se.sum()/len(se))

  print(name + ':MSE = ' + str( mse ))

  #print

  fig = plt.figure(figsize=Figsize)
  ax = fig.add_subplot(111, title=name+str(mse))
  ax.set_xlim(auto=True) #横軸
  ax.set_xlabel("time")
  if ylim != 0: ax.set_ylim(0,ylim)
  else:  ax.set_ylim(auto=True) #縦軸
  ax.set_ylabel("square error")
  ax.plot(se)
  filename = out_path + "/" + name +"@"+ now_str
  if is_save: fig.savefig(filename)
  if is_show: fig.show()
  else:
    plt.clf()
    plt.close()

  return mse

def show_print_array(X,name="no_name",is_show=True,is_save=False,x_lab="time",y_lab="signal",x_lim=True,y_lim=True,grid=True):
  #Figsize,out_pathはglobal変数とする
  fig = plt.figure(figsize=Figsize)
  ax = fig.add_subplot(111, title=name)
  if grid is True:ax.grid(grid)

  if x_lim is True:ax.set_xlim(auto=x_lim) #横軸
  else:ax.set_xlim(x_lim)
  ax.set_xlabel(x_lab)

  if y_lim is True:ax.set_ylim(auto=y_lim) #縦軸
  else:ax.set_ylim(y_lim)
  ax.set_ylabel(y_lab)

  ax.plot(X)
  
  filename = out_path + "/" + name +"@"+ now_str
  if is_save: fig.savefig(filename)
  if is_show: fig.show()
  else:
    plt.clf()
    plt.close()
  return

def show_print_array_for_wout(Wout,name="no_name",is_show=True,is_save=False,x_lab="time",y_lab="signal",x_lim=True,y_lim=True,grid=True):
  #Wout
  #Figsize,out_pathはglobal変数とする
  fig = plt.figure(figsize=Figsize)
  ax = fig.add_subplot(111, title=name)
  if grid is True:ax.grid(grid)

  if x_lim is True:ax.set_xlim(auto=x_lim) #横軸
  else:ax.set_xlim(x_lim)
  ax.set_xlabel(x_lab)

  if y_lim is True:ax.set_ylim(auto=y_lim) #縦軸
  else:ax.set_ylim(y_lim)
  ax.set_ylabel(y_lab)

  ax.bar(np.arange(300), Wout)

  filename = out_path + "/" + name +"@"+ now_str
  if is_save: fig.savefig(filename)
  if is_show: fig.show()
  else:
    plt.clf()
    plt.close()

  return

def show_print_array_for_test(Yt,Y,name="no_name",is_show=True,is_save=False,x_lab="time",y_lab="signal",x_lim=True,y_lim=True,grid=True):
  #Figsize,out_pathはglobal変数とする
  fig = plt.figure(figsize=Figsize)
  ax = fig.add_subplot(111, title=name)
  if grid is True:ax.grid(grid)

  if x_lim is True:ax.set_xlim(auto=x_lim) #横軸
  else:ax.set_xlim(x_lim)
  ax.set_xlabel(x_lab)

  if y_lim is True:ax.set_ylim(auto=y_lim) #縦軸
  else:ax.set_ylim(y_lim)
  ax.set_ylabel(y_lab)

  ax.plot( Yt, 'g' )
  ax.plot( Y, 'b' )

  legends=['Target signal', 'Free-running predicted signal']
  ax.legend(legends)
  
  filename = out_path + "/" + name +"@"+ now_str
  if is_save: fig.savefig(filename)
  if is_show: fig.show()
  else:
    plt.clf()
    plt.close()

  return

def get_MSE(teacher, output):
  se = np.zeros(len(output))
  for i in range(len(output)):
    se[i] =  np.square( output[i] - teacher[i] )

  mse = np.sqrt(se.sum()/len(se))
  return mse

def create_pop_from_differ(data, trainLen, test_t, test_o):
  test_list = []
  out_list=[]
  test_list.append(data[trainLen])
  out_list.append(data[trainLen])
  for i in test_t:
    test = test_list[-1]
    test_list.append(test + i)
  for i in test_o:
    out = out_list[-1]
    out_list.append(out + i)
  return (test_list, out_list)

def sum_pop(df, mesh):
  if type(df) != pd.core.frame.DataFrame:
    print("df is not DataFrame")
    return 0

def complement_linear(start, end, interval = 60):
  #intervalの分、start~endまでを線形補完し、listで返す
  differ = (end - start)/interval
  comp = [i*differ + start for i in range(interval)]
  return comp

"""# df create **4Local**"""

# from google.colab import drive
# drive.mount('/content/drive')
# path = '/content/drive/My Drive/colab/KDDI/'
path = './KDDI/'

df_path = path+"df/"
if not os.path.isdir(df_path):
  os.mkdir(df_path)
if os.path.isfile(df_path+"df.csv"):
  df = pd.read_csv(df_path+"df.csv")
else:
  print("Create DataFrame")
  file = []
  file.append(path)
  file.append(path + 'KLD100101_1.csv')
  file.append(path + 'KLD100102_1.csv')
  file.append(path + 'KLD100103_1.csv')
  file.append(path + 'KLD100104_1.csv')
  file.append(path + 'KLD100105_1.csv')
  file.append(path + 'KLD100106_1.csv')
  
  df1 = pd.read_csv(file[1],header=0)
  #***は10人以下なので0~10人にした
  for i in range(len(df1)):
    if df1.iat[i,7] == "***":
      df1.iat[i,7] = random.uniform(0,10)
    else:
      df1.iat[i,7] = float(df1.iat[i,7])
    
    if df1.iat[i,8] == "***":
      df1.iat[i,8] =  random.uniform(0,10)
    else:
      df1.iat[i,8] = float(df1.iat[i,8])
  df1["sum_population"] = df1["stay_pred_population"] + df1["move_pred_population"]
  print("DF1 Completed")

  df2 = pd.read_csv(file[2],header=0)
  for i in range(len(df2)):
    if df2.iat[i,7] == "***":
      df2.iat[i,7] = random.uniform(0,10)
    else:
      df2.iat[i,7] = float(df2.iat[i,7])
    
    if df2.iat[i,8] == "***":
      df2.iat[i,8] =  random.uniform(0,10)
    else:
      df2.iat[i,8] = float(df2.iat[i,8])
  df2["sum_population"] = df2["stay_pred_population"] + df2["move_pred_population"]
  print("DF2 Completed")

  df3 = pd.read_csv(file[3],header=0)
  for i in range(len(df3)):
    if df3.iat[i,7] == "***":
      df3.iat[i,7] = random.uniform(0,10)
    else:
      df3.iat[i,7] = float(df3.iat[i,7])
    
    if df3.iat[i,8] == "***":
      df3.iat[i,8] =  random.uniform(0,10)
    else:
      df3.iat[i,8] = float(df3.iat[i,8])
  df3["sum_population"] = df3["stay_pred_population"] + df3["move_pred_population"]
  print("DF3 Completed")

  df4 = pd.read_csv(file[4],header=0)
  for i in range(len(df4)):
    if df4.iat[i,7] == "***":
      df4.iat[i,7] = random.uniform(0,10)
    else:
      df4.iat[i,7] = float(df4.iat[i,7])
    
    if df4.iat[i,8] == "***":
      df4.iat[i,8] =  random.uniform(0,10)
    else:
      df4.iat[i,8] = float(df4.iat[i,8])
  df4["sum_population"] = df4["stay_pred_population"] + df4["move_pred_population"]
  print("DF4 Completed")

  df5 = pd.read_csv(file[5],header=0)
  for i in range(len(df5)):
    if df5.iat[i,7] == "***":
      df5.iat[i,7] = random.uniform(0,10)
    else:
      df5.iat[i,7] = float(df5.iat[i,7])
    
    if df5.iat[i,8] == "***":
      df5.iat[i,8] =  random.uniform(0,10)
    else:
      df5.iat[i,8] = float(df5.iat[i,8])
  df5["sum_population"] = df5["stay_pred_population"] + df5["move_pred_population"]
  print("DF5 Completed")

  df6 = pd.read_csv(file[6],header=0)
  for i in range(len(df6)):
    if df6.iat[i,7] == "***":
      df6.iat[i,7] = random.uniform(0,10)
    else:
      df6.iat[i,7] = float(df6.iat[i,7])
    
    if df6.iat[i,8] == "***":
      df6.iat[i,8] =  random.uniform(0,10)
    else:
      df6.iat[i,8] = float(df6.iat[i,8])
  df6["sum_population"] = df6["stay_pred_population"] + df6["move_pred_population"]
  print("DF6 Completed")

  df = df1.copy()
  df = df.append(df2)
  df = df.append(df3)
  df = df.append(df4)
  df = df.append(df5)
  df = df.append(df6)
  df.to_csv(df_path+"df.csv", index=False, header=True)
  print("DF saved")

# df

# marray=df["mesh_code"].unique()
# Smarray=pd.Series(marray//10)
# Smarray=Smarray.unique()
# len(Smarray)

"""# For geo resrvoir input

## mesh_list create
"""

def create_mesh_list(O_mesh):
  ##KDDI　東京都のデータに準拠
  #O_meshはF_meshから1/2地域メッシュまで
  #F_meshが5339で固定してるから渡してない、繰上げも考えてない
  if len(str(O_mesh)) != 9:
    print("error create_mesh_list")
    print(O_mesh)
    return O_mesh

  mesh_list = []
  a_m_dict={}
  a_m_dict[1] = [1,3,2,2,3]
  a_m_dict[2] = [2,4,1,1,4]
  a_m_dict[3] = [3,1,4,4,1]
  a_m_dict[4] = [4,2,3,3,2]

  a_m=int(str(O_mesh)[8])
  mesh_code = int(str(O_mesh)[4:8])

  if a_m == 1:
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][0]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][1]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][2]))
    mesh_list.append(get_mesh("W", mesh_code, a_m_dict[a_m][3]))
    mesh_list.append(get_mesh("S", mesh_code, a_m_dict[a_m][4]))
    return mesh_list
  elif a_m == 2:
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][0]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][1]))
    mesh_list.append(get_mesh("E", mesh_code, a_m_dict[a_m][2]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][3]))
    mesh_list.append(get_mesh("S", mesh_code, a_m_dict[a_m][4]))
    return mesh_list
  elif a_m == 3:
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][0]))
    mesh_list.append(get_mesh("N", mesh_code, a_m_dict[a_m][1]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][2]))
    mesh_list.append(get_mesh("W", mesh_code, a_m_dict[a_m][3]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][4]))
    return mesh_list
  elif a_m == 4:
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][0]))
    mesh_list.append(get_mesh("N", mesh_code, a_m_dict[a_m][1]))
    mesh_list.append(get_mesh("E", mesh_code, a_m_dict[a_m][2]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][3]))
    mesh_list.append(get_mesh("O", mesh_code, a_m_dict[a_m][4]))
    return mesh_list
  else:
    print("error a_m")
    print(a_m)
    return a_m

def get_mesh(direction, mesh_code, a_mesh, F_mesh=5339):
  #地域コードF_mesh+mesh_codeから、directionの方角のセルを取得
  #1/2地域メッシュはa_mesh

  #mesh_codeは第二メッシュコード+第三メッシュコード(判定がばいかも)
  if len(str(mesh_code)) != 4:
    print("error get mesh")
    print(mesh_code)
    return mesh_code
  
  r=F_mesh * 10**5
  s_mesh = str(mesh_code)
  #00,79はなく、第一メッシュに関わる部分はない想定
  lti = int(s_mesh[0])*10 + int(s_mesh[2]) #緯度=たて
  lng = int(s_mesh[1])*10 + int(s_mesh[3]) #軽度=横

  if direction == "O":
    r = r + mesh_code * 10 + a_mesh
    return r
  elif direction == "N":
    lti = lti +1
    r = r + get_STmesh(lti, lng) * 10 + a_mesh
    return r
  elif direction == "E":
    lng = lng +1
    r = r + get_STmesh(lti, lng) * 10 + a_mesh
    return r
  elif direction == "W":
    lng = lng -1
    r = r + get_STmesh(lti, lng) * 10 + a_mesh
    return r
  elif direction == "S":
    lti = lti -1
    r = r + get_STmesh(lti, lng) * 10 + a_mesh
    return r
  else:
    print("direction error")
    print(direction)
    return direction

def get_STmesh(lti, lng):
  #第二第三メッシュコードのlatitudeとlongtitude部分を統合して、メッシュコードとして返す
  #共にintの予定
  STmesh=int(str(lti)[0])*1000 + int(str(lti)[1])*10
  STmesh = STmesh + int(str(lng)[0])*100 + int(str(lng)[1])*1
  return STmesh

def create_mesh_code_list(mesh):
  #meshを中心とした5セルのGeoReservoirに使う5*5のmesh_listのlistを返す
  mesh_code_list=[]
  tmp = create_mesh_list(mesh)
  mesh_code_list.append(tmp)
  for t in tmp[1:]:
    mesh_code_list.append(create_mesh_list(t))
  return mesh_code_list

"""## 使うmesh付近のデータの存在確認"""

def check_mlist(mesh_array):
  # mesh_array=df["mesh_code"].unique()　を入力して、その要素の中から、mlistが作成可能なmeshのリストを返す
  true_mlist=[]
  for m in mesh_array:
    tmp=create_mesh_list(m)
    if not (False in np.in1d(np.array(tmp), mesh_array)):
      true_mlist.append(tmp[0])
  return true_mlist

mesh_code=create_mesh_code_list(533956253)
# mesh_code

"""# 線形補完を5個→9個のセルでして、リストにする

## create_data_from_mesh_list
"""

def create_data_from_mesh_list(df,mesh_list):
  test = df.sort_values(['mesh_code','yyyymm','hour','holiday_flg','gender'])
  data_list = [] #np.array
  test_list = [] #df
  #中央、上、下、？、_
  for tmp_mesh_code in mesh_list:
    #gender,holidayを全て足し合わせて、/2にした
    test_mesh = test[test['mesh_code'] == tmp_mesh_code]
    if len(test_mesh) == 0: print("mesh_code_ERROR")

    tmp_dic = dict(sum_id = [i for i in range(len(test_mesh)//4)])
    df_sum = pd.DataFrame(data=tmp_dic)

    n=0
    mesh_array=test_mesh['mesh_code'].to_numpy()
    sum_array=test_mesh['sum_population'].to_numpy()
    hour_array=test_mesh['hour'].to_numpy()
    day_array=test_mesh['yyyymm'].to_numpy()

    meshcode_list=[]
    sum_list=[]
    hour_list=[]
    day_list=[]
    for i in df_sum['sum_id'].to_numpy():
      n=4*i
      meshcode_list.append(mesh_array[n])
      sum_list.append(sum_array[n])
      day_list.append(day_array[n])
      hour_list.append(hour_array[n])
      for j in [1,2,3]:
        n = 4*i + j
        sum_list[-1] = sum_list[-1] + sum_array[n]
      sum_list[-1] = sum_list[-1]/2

    df_sum['mesh_code'] = np.array(meshcode_list)
    df_sum['sum_population'] = np.array(sum_list)
    df_sum['hour'] = np.array(hour_list)
    df_sum['day'] = np.array(day_list)

    min = [i for _ in range(len(df_sum)-1) for i in range(60)]
    min.append(0) #201901/0:00~2019/06/23:00 (最後は終点がないから補填できない)
    tmp_dic = dict(minutes = min) 
    df_linear = pd.DataFrame(data=tmp_dic)

    l_mesh_list=[]
    l_hour_list=[]
    l_day_list=[]
    l_sum_list=[]

    for df_sum_i in range(len(df_sum)-1):
      tmp = complement_linear(sum_list[df_sum_i],sum_list[df_sum_i+1],60)
      for i in range(60):
        l_mesh_list.append(meshcode_list[df_sum_i])
        l_hour_list.append(hour_list[df_sum_i])
        l_day_list.append(day_list[df_sum_i])

        l_sum_list.append(tmp[i])
      
    l_mesh_list.append(mesh_list[-1])
    l_hour_list.append(hour_list[-1])
    l_day_list.append(day_list[-1])
    l_sum_list.append(sum_list[-1])

    df_linear['mesh_code'] = np.array(l_mesh_list)
    df_linear['sum_population'] = np.array(l_sum_list)
    df_linear['hour'] = np.array(l_hour_list)
    df_linear['day'] = np.array(l_day_list)

    test_list.append(df_linear)
    data_list.append(l_sum_list)
  data = np.array(data_list[0])
  for i in range(1,len(data_list)):
    data = np.vstack((data, np.array(data_list[i])))
  return data

"""## 上記関数からdataのリストを作成"""

data_list=[]
for mesh_list in mesh_code:
  data_list.append(create_data_from_mesh_list(df,mesh_list))

"""# Fig用(fig出力するとき、これ回さないと時刻更新されない)"""

is_update = True

if is_update:
  dt_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))
  now_str = dt_now.strftime('%Y%m%d%H')
  now_day = dt_now.strftime('%Y%m%d')
  out_path = path + "out/"+str(now_day)
  if not os.path.isdir(path+"out"): os.mkdir(path+"out") 
  if not os.path.isdir(out_path): os.mkdir(out_path) #mkdir

print(out_path)

plt.rcParams["font.size"] = 35
Figsize = (40.0, 20.0)

#templete
is_save = False
is_show = False
name = str(mesh_code[0][0]) + "mesh5rawdata"
data = data_list[0]

fig = plt.figure(figsize=Figsize)

ax = fig.add_subplot(111, title=name)
ax.set_xlim(auto=True) #横軸
ax.set_xlabel("time")
ax.set_ylim(auto=True) #縦軸
ax.set_ylabel("population")
ax.plot(data[0:,0:].T)

legends=[i for i in ["O","N","E","W","S"]]
ax.legend(legends)

filename = out_path + "/" + name +"@"+ now_str
if is_save: fig.savefig(filename)

if is_show: fig.show()
else:
  plt.clf()
  plt.close(fig)

#直線用
# ax.axhline(y=6000,xmin=0,xmax=6000,c='r')#縦線
# ax.axvline(x=4000,ymin=0,ymax=7000,c='r')#横線

"""# りざばーコンピューター部

## train
"""

def train_reservoir(res_params,In,Out):
  #InもOutも0:sizeのところを使う
  (leakingRate, resSize, spectralRadius, inSize, outSize, initLen, trainLen, testLen, reg) = res_params
  a = leakingRate
  np.random.seed(42)
  Win = (np.random.rand(resSize,1+inSize) - 0.5) * 1 # -0.5~0.5の一様分布
  W = np.random.rand(resSize,resSize) - 0.5 
  # allocated memory for the design (collected states) matrix
  X = np.zeros((1+resSize,trainLen-initLen))
  # set the corresponding target matrix directly
  Yt = Out[0:outSize,initLen:trainLen] #init ~ train-1でtrain(train-init分)

  # normalizing and setting spectral radius (correct, slow):
  # print('Computing spectral radius...')
  rhoW = max(abs(linalg.eig(W)[0]))
  # print('done.')
  W *= spectralRadius / rhoW
  print("Training...")
  # run the reservoir with the Data and collect X
  x = np.zeros((resSize,1))
  for t in range(trainLen):
    u = In[0:inSize,t:t+1]
    x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) ) #瞬間の値
    if t >= initLen:
        X[:,t-initLen] = np.vstack((1,x))[:,0]

  Wout = linalg.solve( np.dot(X,X.T) + reg*np.eye(1+resSize), np.dot(X,Yt.T) ).T
  return (Win,W,X,Wout,x)

"""## LargeScaleGeoReservoir

### train_LGR
"""

def train_LGR(res_params,raw_data,expIndex,mesh_code,is_update = False):
  (leakingRate, resSize, spectralRadius, inSize, outSize, initLen, trainLen, testLen, reg) = res_params

  train_path=path+"train/"
  if not os.path.isdir(train_path): os.mkdir(train_path)
  train_path=train_path+str(mesh_code)+"/"
  if not os.path.isdir(train_path): os.mkdir(train_path)
  train_path=train_path+"e"+str(expIndex)+"/"
  if not os.path.isdir(train_path): os.mkdir(train_path)

  print
  #mesh_codeのデータがある→読み出し
  Tdata_file = train_path + "Tdata"
  if os.path.isfile(Tdata_file+".npz") and (not is_update):
    Tdata = np.load(Tdata_file+".npz")
    (Win,W,X,Wout,x,Data) = (Tdata["Win"],Tdata["W"],Tdata["X"],Tdata["Wout"],Tdata["x"],Tdata["Data"])
    return (Win,W,X,Wout,x,Data)

  #Train
  Data = raw_data * 10**expIndex
  Data = Data.astype(np.float)
  #trainは1 timeずつ
  In = Data[0:inSize,0:trainLen+testLen-1] #入力
  Out = Data[0:outSize,1:trainLen+testLen] #出力
  a = leakingRate
  np.random.seed(42)
  Win = (np.random.rand(resSize,1+inSize) - 0.5) * 1 # -0.5~0.5の一様分布
  W = np.random.rand(resSize,resSize) - 0.5 
  X = np.zeros((1+resSize,trainLen-initLen))
  Yt = Out[0:outSize,initLen:trainLen] #init ~ train-1でtrain(train-init分)

  # normalizing and setting spectral radius (correct, slow):
  rhoW = max(abs(linalg.eig(W)[0]))
  W *= spectralRadius / rhoW
  print("Training...")
  # run the reservoir with the Data and collect X
  x = np.zeros((resSize,1))
  for t in range(trainLen):
    u = In[0:inSize,t:t+1]
    x = (1-a)*x + a*np.tanh( np.dot( Win, np.vstack((1,u)) ) + np.dot( W, x ) ) #瞬間の値
    if t >= initLen:
        X[:,t-initLen] = np.vstack((1,x))[:,0]
  Wout = linalg.solve( np.dot(X,X.T) + reg*np.eye(1+resSize), np.dot(X,Yt.T) ).T

  #save
  np.savez_compressed(Tdata_file,Win=Win,W=W,X=X,Wout=Wout,x=x,Data=Data)

  return (Win,W,X,Wout,x,Data)

def create_Tdata(res_params,df,expIndex):
  mesh_array=df["mesh_code"].unique()
  tmlist = check_mlist(mesh_array)
  for index,mesh_code in enumerate(tmlist):
    raw_data = create_data_from_mesh_list(df,create_mesh_list(mesh_code))
    _=train_LGR(res_params,raw_data,expIndex,mesh_code)
    print(str(100 * index/len(tmlist) ))
  print("Train Data Saved")
  return

"""### Train Data Just Save"""

res_params = (1, 1000, 0.75, 5, 5, 24*60, 3*24*60, 2*24*60-60+1, 1e-8)
expIndex = -8

start_time = time.perf_counter() #Start
create_Tdata(res_params,df,expIndex)
end_time = time.perf_counter() #End
print("Save Train Data:"+ str(end_time - start_time) + "s")